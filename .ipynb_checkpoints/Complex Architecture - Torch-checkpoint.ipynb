{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'nn';\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'nn'\n",
    "--[[\n",
    "This file contains the code definition of our complex example network in raw Torch\n",
    "using nn.Table modules.  Since nngraph is not used, this network is defined in\n",
    "reverse order in terms of sequential segments and branches.\n",
    "]]--\n",
    "\n",
    "\n",
    "-- the final layer of our base network \n",
    "net3 = nn.Sequential()\n",
    "net3:add(nn.SpatialConvolution(128,256,3,3,1,1,1,1))\n",
    "net3:add(nn.View(-1))\n",
    "\n",
    "-- split the last branch \n",
    "branch2b = nn.ParallelTable()\n",
    "branch2b:add(nn.SpatialConvolution(128,256,3,3,1,1,1,1))\n",
    "branch2b:add(nn.SpatialConvolution(128,256,3,3,1,1,1,1))\n",
    "\n",
    "-- here we add max pooling and use nn.Replicate() --> nn.SplitTable\n",
    "-- to allow for a ParallelTable to split the branch \n",
    "branch2a = nn.Sequential()\n",
    "branch2a:add(nn.SpatialMaxPooling(2,2,2,2))\n",
    "branch2a:add(nn.Replicate(4))\n",
    "branch2a:add(nn.SplitTable(1))\n",
    "branch2a:add(branch2b)\n",
    "\n",
    "-- second (final) branch from base of network\n",
    "branch2 = nn.ParallelTable()\n",
    "branch2:add(branch2a)\n",
    "branch2:add(net3)\n",
    "\n",
    "-- using nn.Sequential() for part 2 of base network \n",
    "net2 = nn.Sequential() \n",
    "net2:add(nn.SpatialConvolution(64,128,3,3,1,1,1,1))\n",
    "net2:add(nn.ReLU())\n",
    "net2:add(nn.SpatialConvolution(128,128,3,3,1,1,1,1))\n",
    "net2:add(nn.ReLU())\n",
    "net2:add(nn.Replicate(4))\n",
    "net2:add(nn.SplitTable(1))\n",
    "net2:add(branch2)\n",
    "\n",
    "-- split from first branch \n",
    "branch1b = nn.ParallelTable()\n",
    "branch1b:add(nn.SpatialConvolution(64,64,3,3,1,1,1,1))\n",
    "branch1b:add(nn.SpatialConvolution(64,64,3,3,1,1,1,1))\n",
    "\n",
    "-- add a max pooling layer to branch and then prepare to split \n",
    "branch1a = nn.Sequential()\n",
    "branch1a:add(nn.SpatialMaxPooling(2,2,2,2))\n",
    "branch1a:add(nn.Replicate(4))\n",
    "branch1a:add(nn.SplitTable(1))\n",
    "branch1a:add(branch1b)\n",
    "\n",
    "-- first branch from the base of the network\n",
    "branch1 = nn.ParallelTable()\n",
    "branch1:add(branch1a)\n",
    "branch1:add(net2)\n",
    "\n",
    "-- the first layers of the network \n",
    "net = nn.Sequential()\n",
    "net:add(nn.SpatialConvolution(3,64,3,3,1,1,1,1))\n",
    "net:add(nn.ReLU())\n",
    "net:add(nn.SpatialConvolution(64,64,3,3,1,1,1,1))\n",
    "net:add(nn.ReLU())\n",
    "net:add(nn.Replicate(4))\n",
    "net:add(nn.SplitTable(1))\n",
    "net:add(branch1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'nn'\n",
    "require 'nngraph'\n",
    "--[[\n",
    "This file contains the code definition of our complex example network using nngraph\n",
    "in combination with some of the nn.Table modules that we defined.\n",
    "]]--\n",
    "\n",
    "input = nn.Identity()() -- \n",
    "\n",
    "L1 = nn.SpatialConvolution(3,64,3,3,1,1,1,1)(input)\n",
    "r1 = nn.ReLU()(L1)\n",
    "L2 = nn.SpatialConvolution(64,64,3,3,1,1,1,1)(r1)\n",
    "r2 = nn.ReLU()(L2)\n",
    "L3 = nn.SpatialConvolution(64,128,3,3,1,1,1,1)(r2)\n",
    "r3 = nn.ReLU()(L3)\n",
    "L4 = nn.SpatialConvolution(128,128,3,3,1,1,1,1)(r3)\n",
    "r4 = nn.ReLU()(L4)\n",
    "r5 = nn.View(-1)(nn.SpatialConvolution(128,256,3,3,1,1,1,1)(r4))\n",
    "\n",
    "b2 = nn.SpatialMaxPooling(2,2,2,2)(r4)\n",
    "b2a = nn.SpatialConvolution(128,256,3,3,1,1,1,1) \n",
    "b2b = nn.SpatialConvolution(128,256,3,3,1,1,1,1)\n",
    "\n",
    "leaf2a = nn.View(-1)(b2a(b2))\n",
    "leaf2b = nn.View(-1)(b2b(b2))\n",
    "\n",
    "leaf2 = nn.JoinTable(1)({leaf2a,leaf2b})\n",
    "\n",
    "b1 = nn.SpatialMaxPooling(2,2,2,2)(r2)\n",
    "b1a = nn.SpatialConvolution(64,64,3,3,1,1,1,1)\n",
    "b1b = nn.SpatialConvolution(64,64,3,3,1,1,1,1)\n",
    "\n",
    "leaf1a = nn.View(-1)(b1a(b1))\n",
    "leaf1b = nn.View(-1)(b1b(b1))\n",
    "\n",
    "leaf1 = nn.JoinTable(1)({leaf1a,leaf1b})\n",
    "\n",
    "output = nn.JoinTable(1)({leaf1,r5,leaf2})\n",
    "\n",
    "net = nn.gModule({input},{output})\n",
    "out = net:forward(torch.Tensor(1,3,10,10))\n",
    "graph.dot(net.fg, 'Forward Graph', 'complexgraph')\n",
    "graph.dot(net.bg, 'Backward Graph','bcomplexgraph')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 41600\n",
       "[torch.LongStorage of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out:size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out = net:forward(torch.Tensor(1,3,10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 25600\n",
       "[torch.LongStorage of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out:size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 40000\n",
       "[torch.LongStorage of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tip1:size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 40000\n",
       "[torch.LongStorage of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tip2:size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input = torch.Tensor(1,3,50,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out = net:forward(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nn.Sequential {\n",
       "  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> output]\n",
       "  (1): nn.SpatialConvolution(3 -> 64, 3x3, 1,1, 1,1)\n",
       "  (2): nn.ReLU\n",
       "  (3): nn.SpatialConvolution(64 -> 64, 3x3, 1,1, 1,1)\n",
       "  (4): nn.Replicate\n",
       "  (5): nn.SplitTable\n",
       "}\n",
       "{\n",
       "  gradInput : DoubleTensor - empty\n",
       "  modules : \n",
       "    {\n",
       "      1 : \n",
       "        nn.SpatialConvolution(3 -> 64, 3x3, 1,1, 1,1)\n",
       "        {\n",
       "          padW : 1\n",
       "          nInputPlane : 3\n",
       "          output : DoubleTensor - size: 1x64x50x50\n",
       "          gradInput : DoubleTensor - empty\n",
       "          _type : torch.DoubleTensor\n"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "          dH : 1\n",
       "          dW : 1\n",
       "          nOutputPlane : 64\n",
       "          padH : 1\n",
       "          kH : 3\n",
       "          finput : DoubleTensor - size: 1x27x2500\n",
       "          weight : DoubleTensor - size: 64x3x3x3\n",
       "          gradWeight : DoubleTensor - size: 64x3x3x3\n",
       "          fgradInput : DoubleTensor - empty\n",
       "          kW : 3\n",
       "          bias : DoubleTensor - size: 64\n",
       "          gradBias : DoubleTensor - size: 64\n",
       "        }\n",
       "      2 : \n",
       "        nn.ReLU\n",
       "        {\n",
       "          inplace : false\n",
       "          threshold : 0\n",
       "          _type : torch.DoubleTensor\n",
       "          output : DoubleTensor - size: 1x64x50x50\n",
       "          gradInput : DoubleTensor - empty\n",
       "          val : 0\n",
       "        }\n",
       "      3 : \n",
       "        nn.SpatialConvolution(64 -> 64, 3x3, 1,1, 1,1)\n",
       "        {\n",
       "          padW : 1\n",
       "          nInputPlane : 64\n",
       "          output : DoubleTensor - size: 1x64x50x50\n",
       "          gradInput : DoubleTensor - empty\n",
       "          _type : torch.DoubleTensor\n",
       "          dH : 1\n",
       "          dW : 1\n",
       "          nOutputPlane : 64\n",
       "          padH : 1\n",
       "          kH : 3\n",
       "          finput : DoubleTensor - size: 1x576x2500\n",
       "          weight : DoubleTensor - size: 64x64x3x3\n",
       "          gradWeight : DoubleTensor - size: 64x64x3x3\n",
       "          fgradInput : DoubleTensor - empty\n",
       "          kW : 3\n",
       "          bias : DoubleTensor - size: 64\n",
       "          gradBias : DoubleTensor - size: 64\n",
       "        }\n",
       "      4 : \n",
       "        nn.Replicate\n",
       "        {\n",
       "          nfeatures : 4\n",
       "          _type : torch.DoubleTensor\n",
       "          output : DoubleTensor - size: 4x1x64x50x50\n",
       "          gradInput : DoubleTensor - empty\n",
       "          dim : 1\n",
       "        }\n",
       "      5 : \n",
       "        nn.SplitTable\n",
       "        {\n",
       "          _type : torch.DoubleTensor\n",
       "          dimension : 1\n",
       "          gradInput : DoubleTensor - empty\n",
       "          output : \n",
       "            {\n",
       "              1 : DoubleTensor - size: 1x64x50x50\n",
       "              2 : DoubleTensor - size: 1x64x50x50\n",
       "              3 : DoubleTensor - size: 1x64x50x50\n",
       "              4 : DoubleTensor - size: 1x64x50x50\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "  _type : torch.DoubleTensor\n",
       "  output : \n",
       "    {\n",
       "      1 : DoubleTensor - size: 1x64x50x50\n",
       "      2 : DoubleTensor - size: 1x64x50x50\n",
       "      3 : DoubleTensor - size: 1x64x50x50\n",
       "      4 : DoubleTensor - size: 1x64x50x50\n",
       "    }\n",
       "}\n"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
